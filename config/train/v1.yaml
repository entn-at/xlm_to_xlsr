group_by_length: True
per_device_train_batch_size: 16
per_device_eval_batch_size: 32
gradient_accumulation_steps: 1
evaluation_strategy: steps
save_strategy: steps
save_steps: 1000
save_total_limit: 2
eval_steps: 1000
max_steps: 100000
fp16: True
fp16_full_eval: True
logging_steps: 10
learning_rate: 2e-4
warmup_steps: 500
lr_scheduler_type: constant_with_warmup
do_train: True
do_eval: True
do_predict: True
metric_for_best_model: wer
greater_is_better: False
seed: 42
