lm_name: xlm-roberta-base
lm_attn_size: 100
sm_attn_size: 499
lm_feat_size: 768
sm_feat_size: 1024

attn_loss: 0.0
feat_loss: 1.0

# w2v2: 25, xlm-roberta-base: 13
feat_target:
  - lm_index: 12
    sm_index: 24
